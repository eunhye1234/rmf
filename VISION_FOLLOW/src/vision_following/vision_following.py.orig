#!/usr/bin/env python3
import cv2
import zmq
import base64
import threading
from queue import Queue, Full, Empty
import numpy as np
import math
import time

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Twist, PoseStamped
from sensor_msgs.msg import LaserScan, Image
from nav2_msgs.action import NavigateToPose
from rclpy.action import ActionClient
from cv_bridge import CvBridge

import tf2_ros
from tf2_geometry_msgs.tf2_geometry_msgs import do_transform_pose
import tf_transformations

from .yolo_tracker import YOLOTracker
from .pid_controller import PIDController
from .lidar_virtual import LidarVirtualizer
from .distance_logger import DistanceLogger

from enum import Enum
class RobotState(Enum):
    IDLE = 0
    FOLLOWING = 1
    SEARCHING = 2

# PID 제어 상수
Kp_ang = 0.005
Kp_lin = 0.002
MAX_LIN_SPEED = 0.3
MAX_ANG_SPEED = 0.5

class VisionFollower(Node):
    def __init__(self):
        super().__init__('vision_follower')

        #-- 파라미터 선언 및 가져오기 (기존과 동일) --
        self.declare_parameter('pseudo_focal_length', 763.5)
        self.declare_parameter('peron_real_width_m', 0.04)
        self.declare_parameter('pid.target_dist', 1.5)

        self.pseudo_focal_length = self.get_parameter('pseudo_focal_length').value
        self.person_width = self.get_parameter('peron_real_width_m').value
        target_dist = self.get_parameter('pid.target_dist').value

        #-- ROS Publisher & Subscriber (기존과 동일) --
        self.cmd_pub = self.create_publisher(Twist, '/cmd_vel', 10)
        self.scan_pub = self.create_publisher(LaserScan, '/scan_virtual', 10)
        self.annotated_image_pub = self.create_publisher(Image, '/annotated_image', 10)
        self.bridge = CvBridge()
        self.create_subscription(LaserScan, '/scan', self.lidar_callback, 1)

        #-- 기능 모듈 초기화 (기존과 동일) --
        self.tracker = YOLOTracker(model_path='yolov10n.pt', 
                                   focal_length=self.pseudo_focal_length, 
                                   person_width=self.person_width)
        self.pid = PIDController(kp_ang=0.01, kp_lin=0.05, target_dist=0.2)
        self.virtualizer = LidarVirtualizer()
        self.logger = DistanceLogger('bbox_distance_log.csv')
        self.nav2_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')

        #-- TF2 (기존과 동일) --
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        #-- 상태 및 변수 초기화 (기존과 동일) --
        self.last_person_pose_3d_cam = None
        self.robot_state = RobotState.IDLE

        #-- ZMQ 소켓을 __init__에서 직접 초기화 --
        self.zmq_context = zmq.Context()
        self.socket = self.zmq_context.socket(zmq.PULL)
        self.socket.bind("tcp://*:5555")
        self.get_logger().info("✅ Vision 서버 시작: 이미지 수신 대기 중...")

        #-- 메인 루프 역할을 할 타이머 생성 (예: 20Hz) --
        self.timer = self.create_timer(0.05, self.main_loop_callback)
        self.get_logger().info("Single-threaded main loop started with timer.")


        # OpenCV 창 설정
        cv2.namedWindow("Received Image", cv2.WINDOW_NORMAL)

        # 루프 실행
        self.process_frames()

    def process_frames(self):
        while rclpy.ok():
            try:
                encoded = self.socket.recv()
                jpg_bytes = base64.b64decode(encoded)
                np_arr = np.frombuffer(jpg_bytes, dtype=np.uint8)
                img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

                if img is None:
                    continue

                results = self.model.predict(source=img, show=False)
                boxes = results[0].boxes
                target_center = None

                for box in boxes:
                    cls_id = int(box.cls[0])
                    if cls_id == 0:  # 사람 class
                        x1, y1, x2, y2 = box.xyxy[0].tolist()
                        center_x = int((x1 + x2) / 2)
                        center_y = int((y1 + y2) / 2)
                        target_center = (center_x, center_y)
                        break  # 첫 번째 사람만 추적

                twist = Twist()

                if target_center:
                    twist = self.pid.compute(center_x, center_y, img)
                    
                else:
                    # 탐지 실패 시 정지
                    twist.linear.x = 0.0
                    twist.angular.z = 0.0
                    self.get_logger().info("⛔️ 사람 탐지 실패. 정지합니다.")

                self.cmd_pub.publish(twist)

                # 결과 시각화
                annotated = results[0].plot()
                cv2.imshow("Received Image", annotated)

                if cv2.waitKey(1) & 0xFF == 27:
                    break

            except KeyboardInterrupt:
                break

        cv2.destroyAllWindows()


